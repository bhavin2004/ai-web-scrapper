# ğŸ•·ï¸ AI Web Scrapper

[![Render Live](https://img.shields.io/badge/demo-live-green?logo=render)](https://ai-web-scrapper-gorl.onrender.com)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/built%20with-Streamlit-red?logo=streamlit)](https://streamlit.io/)

An **AIâ€‘assisted, GUIâ€‘based** webâ€‘scraper that combines **Selenium**, **BeautifulSoup**, and **OpenAI GPTâ€‘4** to pull structured data from almost any website.  
It mimics natural browsing behaviour with **undetectedâ€‘chromedriver**, funnels the rawâ€¯HTML through a lightweight LLM prompt, and delivers tidy CSV output â€“ all wrapped in a oneâ€‘page Streamlit app.

---

## âœ¨ Key Features

| Capability | Details |
|------------|---------|
| ğŸš— **Stealth Scraping** | Launches a headless Chrome via `undetectedâ€‘chromedriver` to reduce botâ€‘detection. |
| ğŸ§  **LLMâ€‘Powered Parsing** | Uses an OpenAI completion to *extract only the fields you describe* and returns valid CSV. |
| ğŸ–¥ï¸ **Streamlit UI** | Oneâ€‘click â€œScrape â†’ Parse â†’ Downloadâ€ workflow â€“ perfect for nonâ€‘coders. |
| ğŸ“¸ **Automatic Screenshot** | Saves a fullâ€‘page PNG every time a page is scraped. |
| â˜ï¸ **Ready for Render** | Ships with a working Render deployment (see live demo above). |

---

## ğŸš€ QuickÂ Start (Local)

1. **Clone & move inside the repo**

```bash
git clone https://github.com/bhavin2004/ai-web-scrapper.git
cd ai-web-scrapper
```

2. **Create a virtual env & install deps**

```bash
python -m venv venv && source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

3. **Add your OpenAI / GitHub token**

Create a `.env` file in the project root:

```dotenv
GITHUB_TOKEN=skâ€‘yourâ€‘tokenâ€‘here
```

The token is used for authenticated calls to the hosted GPTâ€‘4 endpoint inside `parse.py`.

4. **Run the app**

```bash
streamlit run main.py
```

Open the printed local URL (usually http://localhost:8501) in your browser.

---

## ğŸ–¼ï¸ Demo Screenshot

<p align="center">
  <img src="screenshot.png" alt="App screenshot" width="650">
</p>

---

## ğŸ—ï¸ Project Layout

```
.
â”œâ”€â”€ main.py           # Streamlit frontâ€‘end (UI + workflow)
â”œâ”€â”€ scrape.py         # Selenium scraping helpers
â”œâ”€â”€ parse.py          # GPTâ€‘powered parser â†’ CSV
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ .gitignore        # Useful exclusions
â””â”€â”€ screenshot.png    # Example output image
```

---

## âš™ï¸ Howâ€¯Itâ€¯Works

1. **Scrape** â€“ `scrape_website()` opens the target URL, stores `page_source`, and saves a screenshot.  
2. **Clean** â€“ The `<body>` is stripped of script/style tags; text is normalised.  
3. **Chunk** â€“ Large DOMs are split into ~6â€¯kB segments for the model.  
4. **Parse** â€“ Each chunk is sent to GPTâ€‘4 with a strict *â€œCSVâ€‘onlyâ€* system prompt.  
5. **Merge & Download** â€“ Headers are deduplicated, rows concatenated, a CSV is streamed back to the user.

---

## ğŸŒ Oneâ€‘Click Deploy on Render

Create a new **Web Service** on [Render](https://render.com):

| Setting | Value |
|---------|-------|
| **Build Command** | `pip install -r requirements.txt` |
| **Start Command** | `streamlit run main.py --server.port $PORT --server.address 0.0.0.0` |
| **Instance Type** | Starter instance (free tier) |

Ephemeral storage means the CSV is available to download inâ€‘session only â€“ integrate Google Drive or S3 if you need persistence.

---

## ğŸ›£ï¸ Roadmap

- [ ] Multiâ€‘site scraping presets  
- [ ] Proxy rotation & humanâ€‘like mouse movement  
- [ ] Streamlit Cloud deployment  
- [ ] Unit tests (pytest + CI)

---

## ğŸ¤ Contributing

Pull requests are welcome! Please open an issue first to discuss major changes.

1. Fork the repo & create a feature branch (`git checkout -b feat/my-feature`)  
2. Commit your changes (`git commit -am 'Add amazing feature'`)  
3. Push to the branch (`git push origin feat/my-feature`)  
4. Open a PR âœ¨

---

## ğŸ“ License

This project is released under the **MIT License** â€“ see [`LICENSE`](LICENSE) for details.

---

## ğŸ“¬ Contact

**BhavinÂ Karangia** â€“ reach me on [LinkedIn](https://www.linkedin.com/in/bhavin-karangia)  
If you use this project, Iâ€™d love to hear about it!
